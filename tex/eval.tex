\section{Experimental Evaluation}
\label{sec:eval}

\subsection{Obtaining Web Data}
We obtained results through a process of collecting data, and modifying our simulator to output information about the data being processed. 
Mainly, we observed how changes in parameters affected the miss-rate as well as the number of bytes transferred between the proxy and mobile device.
 
In order to collect data over the course of four days, we issued \texttt{telnet} GET requests to various web pages (both desktop and mobile versions) in the morning, afternoon and evening. 
The frequency with which we made these GET requests was for the purpose of reflecting browsing patterns, and it would give us information about the change in the content of a web page over the course of a day and over the course of multiple days. 
We stored each response in a different file and then processed the data to obtain the byte stream version of the HTML pages.

\subsection{Mobile \textit{vs.} Desktop Browser Content}
Many web servers today structure their web pages differently depending on the User-Agent they are serving to increase the speed with which the web pages load, and to provide better service with respect to the UI. 
Therefore, mobile pages are inherently different from their desktop versions and thereby require their own analysis. 
Figure \ref{fig:desktop_mobile} shows the distinctions between mobile web content and desktop web content. The mobile version of \texttt{cnn.com} is only about a fifth of the size of the desktop version. 
The bytes transferred for the unchunked protocol shows that the size of the web page remains relatively constant, and that the entire web page has to be reloaded from the server for each request since the content is no longer ``fresh". 

Figure \ref{fig:desktop_mobile} also shows that the amount of redundancy that is eliminated in both mobile and desktop websites is proportional to the size of the web page. 
It also provides insight into exactly where our protocol performs well, and where the overhead of the protocol takes away from the benefits achieved from chunking. 
We see that on the first visit, the amount of bytes that needs to be transferred is almost twice the size of the actual content. 
This inefficiency comes from the fact that we are using a chunk size of ten bytes. 
During the first visit to \texttt{cnn.com}, when there is no base copy of the web page in the cache, the fingerprints representing the entire web page need to be sent back and forth creating an inefficiency. 
However, once there is a base copy in the cache, the overhead decreases substantially. 
We can see from the graph that by the 12th visit, we are only transferring half the number of bytes as we would need to reload the entire web page. 

\subsection{Effects of Chunk Size}
The use of chunk size of 10 bytes means that each redundant chunk saves 6 bytes because of the 4 bytes of fingerprint needed to represent that chunk. 
This led us to explore different chunk sizes to find the ideal chunk size that takes into consideration the trade-off between having a low cache miss-rate and having a fingerprint map to a bigger chunk.  Figure \ref{fig:percent_content} shows the relationship between the percentage of web content that is needed (based on cache miss-rate and chunk size based on a series of visits to \texttt{cnn.com}. We obtained the data through visits to \texttt{cnn.com} once a day for four days. The first visit is not shown since the cache is empty so 100\% of the contents of the entire web page needs to be transferred for all chunk sizes. 
It is clear from this graph that if we use smaller chunk sizes, the percent of content that needs to be sent decreases. 
The steeper line for chunk 5 when compared to chunk 45 shows that as the number of visits increase, the overlap of smaller chunk sizes increases faster.
However, it means that each fingerprint maps to a smaller chunk and so more fingerprints are needed to represent the small amount of data that needs to be transferred. 

Figure \ref{fig:percent_bytes} takes into account the effects of the extra bytes that are transferred to account for the fingerprints that needs to be transferred to represent redundant chunks. In this graph we can see that as the chunk size increased, the miss-rate also increased as expected, but the bytes transferred actually decreased. 
This is because if the chunk size is small, it becomes expensive for the mobile device to communicate which chunks it needs. 
The ideal chunk size therefore depends on the size of content that needs to be transferred as opposed to percentage.

\subsection{Bandwidth Reduction while Web Browsing.}
Graphs \ref{fig:mob_browsing} and \ref{fig:cumulative} show what happens when we visited three websites three times a day for four days to simulate ``mobile browsing". 
The data was gathered by visiting \texttt{cnn.com}, \texttt{nytimes.com} and \texttt{economist.com} in an alternating basis three times a day over four days. This graph shows that if the base content of each web page is in the cache, then less than 20\% of the content is generally new. The first three requests show that there is some, but not a lot of redundancy between web pages.
Figure \ref{fig:mob_browsing} shows that on the the first visit, the cache is empty and 100\% of the traffic needs to be transferred. 
For the second website, almost all of it needs to be transferred ($~$90\%) because of lack of overlap with the first website. 
On the third, the proportion decreases further but the majority of the page still needs to be transferred. 
After this point, we have the base page for all three websites in our cache and only the differences need to be transferred from the proxy, so the proportion of content that needs to be transferred stays below 20\% by the sixth URL request. 
Figure \ref{fig:mob_browsing} calculates the proportion of content that needs to be transferred based on the cache miss-rate but does not take into account the additional bytes that have to be transferred due to fingerprints.

Figure \ref{fig:cumulative} shows the total number of bytes that were transferred for the 32 requests, including the fingerprints. This shows the bandwidth savings obtained from chunking.
We assume that no response is identical to a previous response. 
This means that without chunking, the full web page has to be reloaded for each request, leading to the linearly increasing number of bytes we see in the graph. 
With chunking however, we see that past the first few requests in which the effects of the overhead are heavy, the number of total bytes transferred rises gradually, and the gap between the bytes transferred grows with the number of requests.

\subsection{Effects of Different Eviction Schemes}
We evaluated the miss-rate of  all cache eviction algorithm schemes described in Section \ref{sec:impl_caching}. We simulated mobile web browsing of three web pages, opening them three times a day in four consecutive days. Then we
measured the miss-rate the the mobile cache has. The results are shown in Figure \ref{fig:cache_missrate}.

%Random
The first thing that we can notice is the poor performance of the random cache eviction scheme. It does not achieve 
good results because it ``blindly'' evicts items from the cache without any consideration of their importance. Probably,
it could be improved by using a non-uniform distribution for the probability with which the items are evicted. However,
we have not found any differentiating factor between the chunks that can serve as a basis of such a distribution.

%LFU
The LFU and LFU-DA schemes do not perform best in our study. We explain this with the fact that recency is more important
than frequency. Since the data from the most recent visit to a web page is needed when requesting information from the 
cache, it is not as relevant how frequently this information is contained in all the visited websites. Another thing that can be
noticed is that the LFU-DA scheme performs even worse than ordinary LFU for a small number of web requests. The reason for this is that it is unlikely that
cache pollution appears in a relatively small number of accesses, as in this experiment. We also performed the same experiment with the LFU-DA scheme for different values of the aging parameter (\textit{e.g.} 2, 10, 50, 250). However, we omitted the results of these experiments from the plot because they are almost the same as for 5 (which is shown). We 
believe that this eviction scheme will be useful for a much longer sequence of web requests where cache pollution actually occurs. It can be seen that it has very good performance at the end of the shown curve. Likely, it will have better performance for longer sequences.

%MRU
As it can also be seen from the figure, the MRU scheme achieves the lowest overall miss-rate. We explain this with the fact that
the cache size is small and when a new website is visited the data from the previous has been evicted. This, in turn, improves the miss-rate for the new website and the overall miss-rate shown on the graph. The same motivation applies for the 
LRU scheme. Since LRU is the opposite of MRU it is impossible for both of them to perform well. 

Another factor that is in favor of the MRU scheme is the implementation complexity and speed. It is one of the easiest to
implement. It does not have to maintain information in efficient data structures such as the LRU or LFU one, for example. 
It is also quite hard to achieve the same speed with LRU, LFU or LFU-DA as for the MRU.

\begin{figure}[h] 
\centering \includegraphics[width=\columnwidth]{images/desktopmobile.png}
\caption{Desktop \textit{vs.} Mobile Browser page differences.}
\label{fig:desktop_mobile}
\end{figure}

\begin{figure}[h] 
\centering \includegraphics[width=\columnwidth]{images/chunksize.png}
\caption{Effects of Chunk Size on portion of content needed.}
\label{fig:percent_content}
\end{figure}

\begin{figure}[h] 
\centering \includegraphics[width=\columnwidth]{images/chunksize2.png}
\caption{Effects of chunk size on Bytes Transferred.}
\label{fig:percent_bytes}
\end{figure}

\begin{figure}[h] 
\centering \includegraphics[width=\columnwidth]{images/browsing.png}
\caption{Mobile Web Browsing.}
\label{fig:mob_browsing}
\end{figure}

\begin{figure}[h] 
\centering \includegraphics[width=\columnwidth]{images/cumulbrowsing.png}
\caption{Cumulative bytes transferred during browsing.}
\label{fig:cumulative}
\end{figure}

\begin{figure}[h]
\centering \includegraphics[width=\columnwidth]{images/caches.pdf}
\caption{Missrate of Different Caches}
\label{fig:cache_missrate}
\end{figure}

